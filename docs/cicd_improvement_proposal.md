# CI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ”¹å–„ææ¡ˆæ›¸

**ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå**: AIä¸»å°å‹ å“çƒãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€å¤§åŒ–ã‚·ã‚¹ãƒ†ãƒ   
**ä½œæˆæ—¥**: 2026å¹´1æœˆ4æ—¥  
**ä½œæˆè€…**: Manus AI

---

## 1. ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼

æœ¬ææ¡ˆæ›¸ã¯ã€ã€Œãƒ†ã‚¹ãƒˆæˆåŠŸå ±å‘Šã¨å®Ÿå‹•ä½œã®ä¹–é›¢ã€ã‚’é˜²ããŸã‚ã®è‡ªå‹•åŒ–ãƒ„ãƒ¼ãƒ«ã¨CI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®æ”¹å–„æ¡ˆã‚’æç¤ºã™ã‚‹ã€‚æ ¸å¿ƒã¨ãªã‚‹æ”¹å–„ã¯ã€**å®Ÿãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ãŸã‚¹ãƒ¢ãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆã®å¿…é ˆåŒ–**ã¨**å¤šå±¤çš„ãªãƒ†ã‚¹ãƒˆã‚²ãƒ¼ãƒˆã®è‡ªå‹•åŒ–**ã§ã‚ã‚‹ã€‚

---

## 2. ç¾çŠ¶ã®å•é¡Œç‚¹

### 2.1 æŠ€è¡“çš„å•é¡Œ

| å•é¡Œ | åŸå›  | å½±éŸ¿ |
|:---|:---|:---|
| ãƒ¢ãƒƒã‚¯ãƒ†ã‚¹ãƒˆã®ã¿ | å®ŸAPIã‚’å‘¼ã³å‡ºã™ãƒ†ã‚¹ãƒˆãŒãªã„ | APIéšœå®³ã‚’æ¤œå‡ºã§ããªã„ |
| é™çš„æ¤œè¨¼ã®ã¿ | å‹•çš„ãªå‹•ä½œç¢ºèªãŒãªã„ | ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚¨ãƒ©ãƒ¼ã‚’æ¤œå‡ºã§ããªã„ |
| æ‰‹å‹•ãƒ‡ãƒ—ãƒ­ã‚¤ | è‡ªå‹•åŒ–ã•ã‚Œã¦ã„ãªã„ | ãƒ’ãƒ¥ãƒ¼ãƒãƒ³ã‚¨ãƒ©ãƒ¼ã®ãƒªã‚¹ã‚¯ |
| ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ä¸è¶³ | ãƒ†ã‚¹ãƒˆçµæœã®ä¿å­˜ãŒãªã„ | äº‹å¾Œæ¤œè¨¼ãŒã§ããªã„ |

### 2.2 ãƒ—ãƒ­ã‚»ã‚¹çš„å•é¡Œ

```
ã€ç¾çŠ¶ã®ãƒ•ãƒ­ãƒ¼ã€‘
é–‹ç™º â†’ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ â†’ ã€ŒæˆåŠŸã€å ±å‘Š â†’ ãƒ‡ãƒ—ãƒ­ã‚¤
         â†‘
    ãƒ¢ãƒƒã‚¯ã®ã¿ã§æ¤œè¨¼
    å®Ÿãƒ‡ãƒ¼ã‚¿ãªã—
    ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ãªã—
```

---

## 3. æ”¹å–„æ¡ˆ: å¤šå±¤ãƒ†ã‚¹ãƒˆã‚²ãƒ¼ãƒˆCI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

### 3.1 ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¦‚è¦

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        CI/CD ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  [ã‚³ãƒŸãƒƒãƒˆ] â†’ [Gate 0] â†’ [Gate 1] â†’ [Gate 2] â†’ [Gate 3] â†’ [ãƒ‡ãƒ—ãƒ­ã‚¤] â”‚
â”‚               ãƒ“ãƒ«ãƒ‰     å˜ä½“       çµ±åˆ       E2E                  â”‚
â”‚               ã‚¹ãƒ¢ãƒ¼ã‚¯   ãƒ†ã‚¹ãƒˆ     ãƒ†ã‚¹ãƒˆ     ãƒ†ã‚¹ãƒˆ                â”‚
â”‚                                                                     â”‚
â”‚  å„ã‚²ãƒ¼ãƒˆã§å¤±æ•— â†’ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åœæ­¢ â†’ é€šçŸ¥ â†’ ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ä¿å­˜           â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 å„ã‚²ãƒ¼ãƒˆã®è©³ç´°

#### Gate 0: ãƒ“ãƒ«ãƒ‰ï¼†ã‚¹ãƒ¢ãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆï¼ˆæœ€é‡è¦ï¼‰

**ç›®çš„**: ã€Œã‚·ã‚¹ãƒ†ãƒ ãŒèµ·å‹•ã—ã€åŸºæœ¬æ©Ÿèƒ½ãŒå‹•ä½œã™ã‚‹ã“ã¨ã€ã‚’ç¢ºèª

```yaml
# .github/workflows/gate0-smoke.yml
name: Gate 0 - Build & Smoke Test

on:
  push:
    branches: [master, develop]
  pull_request:
    branches: [master]

jobs:
  smoke-test:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install pytest pytest-timeout
      
      - name: Download test video
        run: |
          # å®Ÿéš›ã®ãƒ†ã‚¹ãƒˆç”¨å‹•ç”»ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆå°ã‚µã‚¤ã‚ºç‰ˆï¼‰
          curl -L -o tests/fixtures/smoke_test_video.mp4 \
            "${{ secrets.TEST_VIDEO_URL }}"
      
      - name: Run smoke test with REAL video
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          # å®Ÿéš›ã®å‹•ç”»ã‚’ä½¿ç”¨ã—ãŸã‚¹ãƒ¢ãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆ
          python -m pytest tests/smoke/ -v \
            --timeout=300 \
            --tb=long \
            2>&1 | tee smoke_test_output.log
      
      - name: Verify smoke test output
        run: |
          # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒç”Ÿæˆã•ã‚ŒãŸã“ã¨ã‚’ç¢ºèª
          test -f output/analysis_result.json
          test -f output/strategy_sheet.json
          test -f output/practice_plan.json
          
          # JSONãŒæœ‰åŠ¹ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
          python -c "import json; json.load(open('output/analysis_result.json'))"
          python -c "import json; json.load(open('output/strategy_sheet.json'))"
          python -c "import json; json.load(open('output/practice_plan.json'))"
      
      - name: Save evidence
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: gate0-evidence-${{ github.sha }}
          path: |
            smoke_test_output.log
            output/
          retention-days: 30
      
      - name: Notify on failure
        if: failure()
        uses: slackapi/slack-github-action@v1
        with:
          payload: |
            {
              "text": "ğŸš¨ Gate 0 FAILED: Smoke test with real video failed",
              "blocks": [
                {
                  "type": "section",
                  "text": {
                    "type": "mrkdwn",
                    "text": "*Gate 0 Failed*\nCommit: ${{ github.sha }}\nBranch: ${{ github.ref }}\n\nSmoke test with real video failed. System may not be functional."
                  }
                }
              ]
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK }}
```

**ã‚¹ãƒ¢ãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆã®å®Ÿè£…ä¾‹**:

```python
# tests/smoke/test_smoke_real_video.py
"""
ã‚¹ãƒ¢ãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆ: å®Ÿéš›ã®å‹•ç”»ã‚’ä½¿ç”¨ã—ã¦ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ãŒå‹•ä½œã™ã‚‹ã“ã¨ã‚’ç¢ºèª

ã“ã®ãƒ†ã‚¹ãƒˆã¯ä»¥ä¸‹ã‚’æ¤œè¨¼ã™ã‚‹:
1. å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚ã‚‹ã“ã¨
2. ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºãŒæˆåŠŸã™ã‚‹ã“ã¨
3. LLM APIã¸ã®é€ä¿¡ãŒæˆåŠŸã™ã‚‹ã“ã¨
4. åˆ†æçµæœãŒç”Ÿæˆã•ã‚Œã‚‹ã“ã¨
5. æˆ¦ç•¥ã‚·ãƒ¼ãƒˆãŒç”Ÿæˆã•ã‚Œã‚‹ã“ã¨
6. ç·´ç¿’è¨ˆç”»ãŒç”Ÿæˆã•ã‚Œã‚‹ã“ã¨
"""

import pytest
import json
import os
from pathlib import Path

# ãƒ†ã‚¹ãƒˆç”¨å‹•ç”»ã®ãƒ‘ã‚¹
SMOKE_TEST_VIDEO = Path("tests/fixtures/smoke_test_video.mp4")
OUTPUT_DIR = Path("output")


class TestSmokeRealVideo:
    """å®Ÿå‹•ç”»ã‚’ä½¿ç”¨ã—ãŸã‚¹ãƒ¢ãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆ"""
    
    @pytest.fixture(autouse=True)
    def setup(self):
        """ãƒ†ã‚¹ãƒˆå‰ã®æº–å‚™"""
        OUTPUT_DIR.mkdir(exist_ok=True)
        assert SMOKE_TEST_VIDEO.exists(), f"ãƒ†ã‚¹ãƒˆå‹•ç”»ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {SMOKE_TEST_VIDEO}"
    
    def test_video_analysis_completes(self):
        """å‹•ç”»åˆ†æãŒå®Œäº†ã™ã‚‹ã“ã¨"""
        from src.analysis.video_analyzer import VideoAnalyzer
        
        analyzer = VideoAnalyzer()
        result = analyzer.analyze(str(SMOKE_TEST_VIDEO))
        
        # çµæœãŒNoneã§ãªã„ã“ã¨
        assert result is not None, "åˆ†æçµæœãŒNoneã§ã™"
        
        # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒå­˜åœ¨ã™ã‚‹ã“ã¨
        assert "åŸºæœ¬æƒ…å ±" in result, "åŸºæœ¬æƒ…å ±ãŒå­˜åœ¨ã—ã¾ã›ã‚“"
        assert "æŠ€è¡“è©•ä¾¡" in result, "æŠ€è¡“è©•ä¾¡ãŒå­˜åœ¨ã—ã¾ã›ã‚“"
        assert "æˆ¦è¡“åˆ†æ" in result, "æˆ¦è¡“åˆ†æãŒå­˜åœ¨ã—ã¾ã›ã‚“"
        
        # çµæœã‚’ä¿å­˜
        with open(OUTPUT_DIR / "analysis_result.json", "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
    
    def test_strategy_generation_completes(self):
        """æˆ¦ç•¥ã‚·ãƒ¼ãƒˆç”ŸæˆãŒå®Œäº†ã™ã‚‹ã“ã¨"""
        from src.strategy.generator import StrategyGenerator
        
        # åˆ†æçµæœã‚’èª­ã¿è¾¼ã¿
        with open(OUTPUT_DIR / "analysis_result.json", "r", encoding="utf-8") as f:
            analysis = json.load(f)
        
        generator = StrategyGenerator()
        result = generator.generate(analysis)
        
        # çµæœãŒNoneã§ãªã„ã“ã¨
        assert result is not None, "æˆ¦ç•¥ã‚·ãƒ¼ãƒˆãŒNoneã§ã™"
        
        # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒå­˜åœ¨ã™ã‚‹ã“ã¨
        assert "ã‚µãƒ¼ãƒ–æˆ¦ç•¥" in result or "1.ã‚µãƒ¼ãƒ–æˆ¦ç•¥" in result, "ã‚µãƒ¼ãƒ–æˆ¦ç•¥ãŒå­˜åœ¨ã—ã¾ã›ã‚“"
        
        # çµæœã‚’ä¿å­˜
        with open(OUTPUT_DIR / "strategy_sheet.json", "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
    
    def test_practice_plan_generation_completes(self):
        """ç·´ç¿’è¨ˆç”»ç”ŸæˆãŒå®Œäº†ã™ã‚‹ã“ã¨"""
        from src.practice.planner import PracticePlanner
        
        # åˆ†æçµæœã‚’èª­ã¿è¾¼ã¿
        with open(OUTPUT_DIR / "analysis_result.json", "r", encoding="utf-8") as f:
            analysis = json.load(f)
        
        planner = PracticePlanner()
        result = planner.generate(analysis)
        
        # çµæœãŒNoneã§ãªã„ã“ã¨
        assert result is not None, "ç·´ç¿’è¨ˆç”»ãŒNoneã§ã™"
        
        # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒå­˜åœ¨ã™ã‚‹ã“ã¨
        assert "å„ªå…ˆèª²é¡Œ" in result, "å„ªå…ˆèª²é¡ŒãŒå­˜åœ¨ã—ã¾ã›ã‚“"
        assert "é€±é–“è¨ˆç”»" in result, "é€±é–“è¨ˆç”»ãŒå­˜åœ¨ã—ã¾ã›ã‚“"
        
        # çµæœã‚’ä¿å­˜
        with open(OUTPUT_DIR / "practice_plan.json", "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
    
    def test_output_quality_basic(self):
        """å‡ºåŠ›ã®åŸºæœ¬å“è³ªã‚’ç¢ºèª"""
        # åˆ†æçµæœã®å“è³ªç¢ºèª
        with open(OUTPUT_DIR / "analysis_result.json", "r", encoding="utf-8") as f:
            analysis = json.load(f)
        
        # åˆ©ãæ‰‹ãŒæœ‰åŠ¹ãªå€¤ã§ã‚ã‚‹ã“ã¨
        dominant_hand = analysis.get("åŸºæœ¬æƒ…å ±", {}).get("åˆ©ãæ‰‹", "")
        assert dominant_hand in ["å³", "å·¦"], f"åˆ©ãæ‰‹ãŒä¸æ­£: {dominant_hand}"
        
        # ã‚°ãƒªãƒƒãƒ—ãŒæœ‰åŠ¹ãªå€¤ã§ã‚ã‚‹ã“ã¨
        grip = analysis.get("åŸºæœ¬æƒ…å ±", {}).get("ã‚°ãƒªãƒƒãƒ—", "")
        assert grip in ["ã‚·ã‚§ãƒ¼ã‚¯ãƒãƒ³ãƒ‰", "ãƒšãƒ³ãƒ›ãƒ«ãƒ€ãƒ¼", "ã‚·ã‚§ã‚¤ã‚¯ãƒãƒ³ãƒ‰"], f"ã‚°ãƒªãƒƒãƒ—ãŒä¸æ­£: {grip}"
        
        # æŠ€è¡“è©•ä¾¡ãŒ1-5ã®ç¯„å›²ã§ã‚ã‚‹ã“ã¨
        tech_eval = analysis.get("æŠ€è¡“è©•ä¾¡", {})
        for skill, score in tech_eval.items():
            if isinstance(score, (int, float)):
                assert 1 <= score <= 5, f"{skill}ã®ã‚¹ã‚³ã‚¢ãŒç¯„å›²å¤–: {score}"
```

#### Gate 1: å˜ä½“ãƒ†ã‚¹ãƒˆ

```yaml
# .github/workflows/gate1-unit.yml
name: Gate 1 - Unit Tests

on:
  workflow_run:
    workflows: ["Gate 0 - Build & Smoke Test"]
    types: [completed]

jobs:
  unit-tests:
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: pip install -r requirements.txt -r requirements-dev.txt
      
      - name: Run unit tests with coverage
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          python -m pytest tests/unit/ \
            -v \
            --cov=src \
            --cov-report=xml \
            --cov-report=html \
            --cov-fail-under=80 \
            2>&1 | tee unit_test_output.log
      
      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          file: coverage.xml
          fail_ci_if_error: true
      
      - name: Save evidence
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: gate1-evidence-${{ github.sha }}
          path: |
            unit_test_output.log
            htmlcov/
            coverage.xml
```

#### Gate 2: çµ±åˆãƒ†ã‚¹ãƒˆ

```yaml
# .github/workflows/gate2-integration.yml
name: Gate 2 - Integration Tests

on:
  workflow_run:
    workflows: ["Gate 1 - Unit Tests"]
    types: [completed]

jobs:
  integration-tests:
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: pip install -r requirements.txt -r requirements-dev.txt
      
      - name: Download test fixtures
        run: |
          curl -L -o tests/fixtures/integration_test_video.mp4 \
            "${{ secrets.TEST_VIDEO_URL }}"
      
      - name: Run integration tests with REAL API
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          USE_REAL_API: "true"
        run: |
          python -m pytest tests/integration/ \
            -v \
            --timeout=600 \
            -m "not slow" \
            2>&1 | tee integration_test_output.log
      
      - name: Validate integration outputs
        run: |
          python scripts/validate_integration_outputs.py
      
      - name: Save evidence
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: gate2-evidence-${{ github.sha }}
          path: |
            integration_test_output.log
            tests/integration/output/
```

#### Gate 3: E2Eãƒ†ã‚¹ãƒˆ

```yaml
# .github/workflows/gate3-e2e.yml
name: Gate 3 - E2E Tests

on:
  workflow_run:
    workflows: ["Gate 2 - Integration Tests"]
    types: [completed]

jobs:
  e2e-tests:
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    runs-on: ubuntu-latest
    timeout-minutes: 45
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: pip install -r requirements.txt -r requirements-dev.txt
      
      - name: Download E2E test fixtures
        run: |
          # è¤‡æ•°ã®ãƒ†ã‚¹ãƒˆå‹•ç”»ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
          curl -L -o tests/fixtures/e2e_video_1.mp4 "${{ secrets.E2E_VIDEO_1_URL }}"
          curl -L -o tests/fixtures/e2e_video_2.mp4 "${{ secrets.E2E_VIDEO_2_URL }}"
      
      - name: Run E2E tests with REAL videos
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          python -m pytest tests/e2e/ \
            -v \
            --timeout=900 \
            2>&1 | tee e2e_test_output.log
      
      - name: Generate E2E test report
        run: |
          python scripts/generate_e2e_report.py \
            --output reports/e2e_report.html
      
      - name: Save evidence
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: gate3-evidence-${{ github.sha }}
          path: |
            e2e_test_output.log
            tests/e2e/output/
            reports/
      
      - name: Notify success
        if: success()
        uses: slackapi/slack-github-action@v1
        with:
          payload: |
            {
              "text": "âœ… All Gates Passed! Ready for deployment.",
              "blocks": [
                {
                  "type": "section",
                  "text": {
                    "type": "mrkdwn",
                    "text": "*All Gates Passed*\nCommit: ${{ github.sha }}\n\nâœ… Gate 0: Smoke Test\nâœ… Gate 1: Unit Tests\nâœ… Gate 2: Integration Tests\nâœ… Gate 3: E2E Tests"
                  }
                }
              ]
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK }}
```

---

## 4. ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹è‡ªå‹•åé›†ã‚·ã‚¹ãƒ†ãƒ 

### 4.1 ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹åé›†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

```python
# scripts/collect_evidence.py
"""
ãƒ†ã‚¹ãƒˆã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹è‡ªå‹•åé›†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

å„ãƒ†ã‚¹ãƒˆå®Ÿè¡Œå¾Œã«ä»¥ä¸‹ã‚’åé›†:
1. å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®ãƒ¡ã‚¿æƒ…å ±
2. å®Ÿè¡Œãƒ­ã‚°
3. å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿
4. ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰
5. ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
"""

import json
import hashlib
import datetime
from pathlib import Path
from dataclasses import dataclass, asdict
from typing import Optional, List, Dict, Any


@dataclass
class TestEvidence:
    """ãƒ†ã‚¹ãƒˆã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ """
    test_id: str
    test_name: str
    timestamp: str
    duration_seconds: float
    status: str  # "passed", "failed", "skipped"
    
    # å…¥åŠ›
    input_files: List[Dict[str, Any]]  # ãƒ•ã‚¡ã‚¤ãƒ«åã€ã‚µã‚¤ã‚ºã€ãƒãƒƒã‚·ãƒ¥
    input_parameters: Dict[str, Any]
    
    # å®Ÿè¡Œ
    execution_log: str
    error_message: Optional[str]
    
    # å‡ºåŠ›
    output_files: List[Dict[str, Any]]  # ãƒ•ã‚¡ã‚¤ãƒ«åã€ã‚µã‚¤ã‚ºã€ãƒãƒƒã‚·ãƒ¥
    output_summary: Dict[str, Any]
    
    # æ¤œè¨¼
    assertions: List[Dict[str, Any]]  # å„ã‚¢ã‚µãƒ¼ã‚·ãƒ§ãƒ³ã®çµæœ
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
    git_commit: str
    git_branch: str
    environment: Dict[str, str]


class EvidenceCollector:
    """ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹åé›†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, output_dir: str = "evidence"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
    
    def collect_file_info(self, file_path: str) -> Dict[str, Any]:
        """ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’åé›†"""
        path = Path(file_path)
        if not path.exists():
            return {"path": file_path, "exists": False}
        
        with open(path, "rb") as f:
            content = f.read()
            file_hash = hashlib.sha256(content).hexdigest()
        
        return {
            "path": file_path,
            "exists": True,
            "size_bytes": path.stat().st_size,
            "sha256": file_hash,
            "modified_at": datetime.datetime.fromtimestamp(
                path.stat().st_mtime
            ).isoformat()
        }
    
    def save_evidence(self, evidence: TestEvidence) -> str:
        """ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ã‚’ä¿å­˜"""
        filename = f"{evidence.timestamp}_{evidence.test_id}.json"
        filepath = self.output_dir / filename
        
        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(asdict(evidence), f, ensure_ascii=False, indent=2)
        
        return str(filepath)
    
    def generate_report(self, evidences: List[TestEvidence]) -> str:
        """ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        report = {
            "generated_at": datetime.datetime.now().isoformat(),
            "total_tests": len(evidences),
            "passed": sum(1 for e in evidences if e.status == "passed"),
            "failed": sum(1 for e in evidences if e.status == "failed"),
            "skipped": sum(1 for e in evidences if e.status == "skipped"),
            "tests": [asdict(e) for e in evidences]
        }
        
        report_path = self.output_dir / f"report_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_path, "w", encoding="utf-8") as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        return str(report_path)
```

### 4.2 pytest ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã¨ã—ã¦ã®å®Ÿè£…

```python
# conftest.py
"""
pytestç”¨ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹åé›†ãƒ—ãƒ©ã‚°ã‚¤ãƒ³
"""

import pytest
import json
import time
import subprocess
from pathlib import Path
from scripts.collect_evidence import EvidenceCollector, TestEvidence


@pytest.fixture(scope="session")
def evidence_collector():
    """ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹åé›†å™¨ã®ãƒ•ã‚£ã‚¯ã‚¹ãƒãƒ£"""
    return EvidenceCollector(output_dir="evidence")


@pytest.hookimpl(tryfirst=True, hookwrapper=True)
def pytest_runtest_makereport(item, call):
    """å„ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œçµæœã‚’åé›†"""
    outcome = yield
    report = outcome.get_result()
    
    if report.when == "call":
        # ãƒ†ã‚¹ãƒˆçµæœã‚’ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ã¨ã—ã¦ä¿å­˜
        evidence_dir = Path("evidence")
        evidence_dir.mkdir(exist_ok=True)
        
        evidence = {
            "test_name": item.name,
            "test_file": str(item.fspath),
            "status": report.outcome,
            "duration": report.duration,
            "timestamp": time.strftime("%Y-%m-%dT%H:%M:%S"),
            "git_commit": subprocess.getoutput("git rev-parse HEAD"),
            "git_branch": subprocess.getoutput("git branch --show-current"),
        }
        
        if report.failed:
            evidence["error"] = str(report.longrepr)
        
        # ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ã‚’ä¿å­˜
        evidence_file = evidence_dir / f"{item.name}_{int(time.time())}.json"
        with open(evidence_file, "w", encoding="utf-8") as f:
            json.dump(evidence, f, ensure_ascii=False, indent=2)
```

---

## 5. å®Ÿãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 

### 5.1 ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãƒªãƒã‚¸ãƒˆãƒª

```yaml
# .github/workflows/sync-test-data.yml
name: Sync Test Data

on:
  schedule:
    - cron: '0 0 * * 0'  # æ¯é€±æ—¥æ›œæ—¥
  workflow_dispatch:

jobs:
  sync-test-data:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Download test videos from S3
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        run: |
          aws s3 sync s3://tt-performance-test-data/videos/ tests/fixtures/videos/
      
      - name: Verify test data integrity
        run: |
          python scripts/verify_test_data.py
      
      - name: Update test data manifest
        run: |
          python scripts/update_manifest.py
```

### 5.2 ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆ

```json
// tests/fixtures/manifest.json
{
  "version": "1.0.0",
  "updated_at": "2026-01-04T00:00:00Z",
  "videos": [
    {
      "id": "smoke_test_video",
      "filename": "smoke_test_video.mp4",
      "description": "ã‚¹ãƒ¢ãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆç”¨ã®çŸ­ã„è©¦åˆå‹•ç”»ï¼ˆ30ç§’ï¼‰",
      "duration_seconds": 30,
      "size_bytes": 5242880,
      "sha256": "abc123...",
      "player_info": {
        "dominant_hand": "å³",
        "grip": "ã‚·ã‚§ãƒ¼ã‚¯ãƒãƒ³ãƒ‰",
        "play_style": "ãƒ‰ãƒ©ã‚¤ãƒ–ä¸»æˆ¦å‹"
      },
      "expected_outputs": {
        "analysis": {
          "dominant_hand": "å³",
          "grip": "ã‚·ã‚§ãƒ¼ã‚¯ãƒãƒ³ãƒ‰"
        }
      }
    },
    {
      "id": "integration_test_video",
      "filename": "integration_test_video.mp4",
      "description": "çµ±åˆãƒ†ã‚¹ãƒˆç”¨ã®è©¦åˆå‹•ç”»ï¼ˆ3åˆ†ï¼‰",
      "duration_seconds": 180,
      "size_bytes": 52428800,
      "sha256": "def456..."
    }
  ]
}
```

---

## 6. ç›£è¦–ã¨ã‚¢ãƒ©ãƒ¼ãƒˆ

### 6.1 ãƒ†ã‚¹ãƒˆå“è³ªãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰

```python
# scripts/generate_dashboard.py
"""
ãƒ†ã‚¹ãƒˆå“è³ªãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import json
from pathlib import Path
from datetime import datetime, timedelta


def generate_dashboard():
    """ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰HTMLã‚’ç”Ÿæˆ"""
    evidence_dir = Path("evidence")
    evidences = []
    
    for file in evidence_dir.glob("*.json"):
        with open(file) as f:
            evidences.append(json.load(f))
    
    # éå»7æ—¥é–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’é›†è¨ˆ
    recent = [e for e in evidences 
              if datetime.fromisoformat(e["timestamp"]) > datetime.now() - timedelta(days=7)]
    
    stats = {
        "total": len(recent),
        "passed": sum(1 for e in recent if e["status"] == "passed"),
        "failed": sum(1 for e in recent if e["status"] == "failed"),
        "pass_rate": sum(1 for e in recent if e["status"] == "passed") / len(recent) * 100 if recent else 0
    }
    
    # HTMLãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’ç”Ÿæˆ
    html = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <title>Test Quality Dashboard</title>
        <style>
            body {{ font-family: Arial, sans-serif; margin: 20px; }}
            .stats {{ display: flex; gap: 20px; }}
            .stat-card {{ padding: 20px; border-radius: 8px; background: #f5f5f5; }}
            .stat-card.passed {{ background: #d4edda; }}
            .stat-card.failed {{ background: #f8d7da; }}
            .stat-value {{ font-size: 2em; font-weight: bold; }}
        </style>
    </head>
    <body>
        <h1>Test Quality Dashboard</h1>
        <p>Generated: {datetime.now().isoformat()}</p>
        
        <div class="stats">
            <div class="stat-card">
                <div class="stat-value">{stats['total']}</div>
                <div>Total Tests (7 days)</div>
            </div>
            <div class="stat-card passed">
                <div class="stat-value">{stats['passed']}</div>
                <div>Passed</div>
            </div>
            <div class="stat-card failed">
                <div class="stat-value">{stats['failed']}</div>
                <div>Failed</div>
            </div>
            <div class="stat-card">
                <div class="stat-value">{stats['pass_rate']:.1f}%</div>
                <div>Pass Rate</div>
            </div>
        </div>
        
        <h2>Recent Test Results</h2>
        <table border="1" cellpadding="8">
            <tr>
                <th>Test Name</th>
                <th>Status</th>
                <th>Duration</th>
                <th>Timestamp</th>
            </tr>
            {"".join(f'''
            <tr>
                <td>{e.get("test_name", "N/A")}</td>
                <td style="color: {'green' if e['status'] == 'passed' else 'red'}">{e['status']}</td>
                <td>{e.get("duration", 0):.2f}s</td>
                <td>{e.get("timestamp", "N/A")}</td>
            </tr>
            ''' for e in sorted(recent, key=lambda x: x.get("timestamp", ""), reverse=True)[:20])}
        </table>
    </body>
    </html>
    """
    
    with open("reports/dashboard.html", "w") as f:
        f.write(html)


if __name__ == "__main__":
    generate_dashboard()
```

### 6.2 ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®š

```yaml
# .github/workflows/alert-on-failure.yml
name: Alert on Test Failure

on:
  workflow_run:
    workflows: ["Gate 0 - Build & Smoke Test", "Gate 1 - Unit Tests", "Gate 2 - Integration Tests", "Gate 3 - E2E Tests"]
    types: [completed]

jobs:
  alert:
    if: ${{ github.event.workflow_run.conclusion == 'failure' }}
    runs-on: ubuntu-latest
    
    steps:
      - name: Send Slack Alert
        uses: slackapi/slack-github-action@v1
        with:
          payload: |
            {
              "text": "ğŸš¨ Test Pipeline Failed",
              "blocks": [
                {
                  "type": "section",
                  "text": {
                    "type": "mrkdwn",
                    "text": "*Test Pipeline Failed*\n\nWorkflow: ${{ github.event.workflow_run.name }}\nCommit: ${{ github.event.workflow_run.head_sha }}\nBranch: ${{ github.event.workflow_run.head_branch }}\n\n<${{ github.event.workflow_run.html_url }}|View Details>"
                  }
                }
              ]
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK }}
      
      - name: Create GitHub Issue
        uses: actions/github-script@v7
        with:
          script: |
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `ğŸš¨ Test Failure: ${context.payload.workflow_run.name}`,
              body: `## Test Pipeline Failed
              
              - **Workflow**: ${context.payload.workflow_run.name}
              - **Commit**: ${context.payload.workflow_run.head_sha}
              - **Branch**: ${context.payload.workflow_run.head_branch}
              - **Details**: ${context.payload.workflow_run.html_url}
              
              Please investigate and fix the issue.`,
              labels: ['bug', 'test-failure', 'high-priority']
            })
```

---

## 7. å°å…¥ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—

### 7.1 ãƒ•ã‚§ãƒ¼ã‚ºåˆ¥å°å…¥è¨ˆç”»

| ãƒ•ã‚§ãƒ¼ã‚º | æœŸé–“ | å†…å®¹ | æˆæœç‰© |
|:---|:---|:---|:---|
| Phase 1 | 1é€±é–“ | Gate 0ï¼ˆã‚¹ãƒ¢ãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆï¼‰ã®å°å…¥ | smoke test workflow |
| Phase 2 | 1é€±é–“ | ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹åé›†ã‚·ã‚¹ãƒ†ãƒ ã®å°å…¥ | evidence collector |
| Phase 3 | 1é€±é–“ | Gate 1-3ã®è‡ªå‹•åŒ– | full CI/CD pipeline |
| Phase 4 | 1é€±é–“ | ç›£è¦–ãƒ»ã‚¢ãƒ©ãƒ¼ãƒˆã®å°å…¥ | dashboard, alerts |

### 7.2 å¿…è¦ãªãƒªã‚½ãƒ¼ã‚¹

| ãƒªã‚½ãƒ¼ã‚¹ | ç”¨é€” | è¦‹ç©ã‚‚ã‚Šã‚³ã‚¹ãƒˆ |
|:---|:---|:---|
| GitHub Actions | CI/CDå®Ÿè¡Œ | ç„¡æ–™ï¼ˆãƒ‘ãƒ–ãƒªãƒƒã‚¯ãƒªãƒã‚¸ãƒˆãƒªï¼‰ |
| AWS S3 | ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä¿å­˜ | $5/æœˆ |
| Slack | ã‚¢ãƒ©ãƒ¼ãƒˆé€šçŸ¥ | ç„¡æ–™ |
| OpenAI API | ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ | $10-50/æœˆï¼ˆãƒ†ã‚¹ãƒˆé »åº¦ã«ã‚ˆã‚‹ï¼‰ |

---

## 8. çµè«–

æœ¬ææ¡ˆã®æ ¸å¿ƒã¯ã€**ã€Œå®Ÿãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ãŸã‚¹ãƒ¢ãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆã‚’CI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®æœ€åˆã®ã‚²ãƒ¼ãƒˆã¨ã—ã¦å¿…é ˆåŒ–ã™ã‚‹ã€**ã“ã¨ã§ã‚ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã€Œãƒ†ã‚¹ãƒˆã¯é€šã‚‹ãŒå®Ÿéš›ã«ã¯å‹•ã‹ãªã„ã€ã¨ã„ã†å•é¡Œã‚’æ ¹æœ¬çš„ã«é˜²æ­¢ã§ãã‚‹ã€‚

### ä¸»è¦ãªæ”¹å–„ç‚¹

1. **Gate 0ï¼ˆã‚¹ãƒ¢ãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆï¼‰ã®æ–°è¨­**: å®Ÿå‹•ç”»ã‚’ä½¿ç”¨ã—ãŸå‹•ä½œç¢ºèªã‚’æœ€åˆã«å®Ÿæ–½
2. **ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹è‡ªå‹•åé›†**: å…¥åŠ›ãƒ»å‡ºåŠ›ãƒ»ãƒ­ã‚°ã‚’è‡ªå‹•ä¿å­˜
3. **å¤šå±¤ã‚²ãƒ¼ãƒˆ**: å„ã‚²ãƒ¼ãƒˆã‚’é€šéã—ãªã„ã¨æ¬¡ã«é€²ã‚ãªã„
4. **ç›£è¦–ãƒ»ã‚¢ãƒ©ãƒ¼ãƒˆ**: å¤±æ•—æ™‚ã®å³åº§ã®é€šçŸ¥ã¨Issueä½œæˆ

### æœŸå¾…ã•ã‚Œã‚‹åŠ¹æœ

- ã€Œãƒ†ã‚¹ãƒˆæˆåŠŸå ±å‘Šã¨å®Ÿå‹•ä½œã®ä¹–é›¢ã€ã®é˜²æ­¢
- å•é¡Œã®æ—©æœŸç™ºè¦‹
- ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ã«åŸºã¥ãå“è³ªä¿è¨¼
- é–‹ç™ºè€…ã®ä¿¡é ¼æ€§å‘ä¸Š
